"""ANA Custom Error Module.

Provides user-friendly error messages with solution suggestions.
"""

from rich.console import Console
from rich.panel import Panel

console = Console()


class ANAError(Exception):
    """Base error class for ANA with user-friendly messages."""
    
    def __init__(self, message: str, solution: str | None = None, details: str | None = None):
        self.message = message
        self.solution = solution
        self.details = details
        super().__init__(message)
    
    def display(self) -> None:
        """Display error with rich formatting."""
        content = f"[bold red]âŒ {self.message}[/bold red]"
        
        if self.details:
            content += f"\n\n[dim]{self.details}[/dim]"
        
        if self.solution:
            content += f"\n\n[bold green]ğŸ’¡ í•´ê²° ë°©ë²•:[/bold green]\n{self.solution}"
        
        console.print(Panel(content, title="ì˜¤ë¥˜ ë°œìƒ", border_style="red"))


class ConfigurationError(ANAError):
    """Configuration related errors."""
    pass


class APIKeyError(ConfigurationError):
    """API key related errors."""
    
    def __init__(self, provider: str):
        providers_info = {
            "openai": (
                "OPENAI_API_KEY",
                "https://platform.openai.com/api-keys ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”."
            ),
            "anthropic": (
                "ANTHROPIC_API_KEY", 
                "https://console.anthropic.com/settings/keys ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”."
            ),
            "ollama": (
                None,
                "OllamaëŠ” API í‚¤ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”:\n   ollama serve"
            ),
            "vllm": (
                None,
                "vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
            ),
        }
        
        env_var, guide = providers_info.get(provider, ("UNKNOWN", "ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."))
        
        if env_var:
            message = f"{provider.upper()} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            solution = (
                f"1. .env íŒŒì¼ì— {env_var}ë¥¼ ì„¤ì •í•˜ì„¸ìš”\n"
                f"2. {guide}\n"
                f"3. ë˜ëŠ” ë¬´ë£Œë¡œ Ollamaë¥¼ ì‚¬ìš©í•˜ì„¸ìš”: ana config set llm_provider ollama"
            )
        else:
            message = f"{provider.upper()} ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            solution = guide
            
        super().__init__(message, solution)
        self.provider = provider


class VaultPathError(ConfigurationError):
    """Vault path related errors."""
    
    def __init__(self, path: str, reason: str = "not_found"):
        reasons = {
            "not_found": f"Vault ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}",
            "not_directory": f"Vault ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {path}",
            "no_permission": f"Vault ê²½ë¡œì— ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {path}",
        }
        
        message = reasons.get(reason, f"Vault ê²½ë¡œ ì˜¤ë¥˜: {path}")
        solution = (
            "1. Obsidianì—ì„œ Vault ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš” (ì„¤ì • > íŒŒì¼ ë° ë§í¬ > Vault ìœ„ì¹˜)\n"
            "2. .env íŒŒì¼ì—ì„œ ANA_VAULT_PATHë¥¼ ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”\n"
            "3. ë˜ëŠ” ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •: ana config set vault_path /your/vault/path"
        )
        
        super().__init__(message, solution)
        self.path = path
        self.reason = reason


class LLMConnectionError(ANAError):
    """LLM connection related errors."""
    
    def __init__(self, provider: str, base_url: str | None = None):
        message = f"{provider.upper()} ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        if provider == "ollama":
            solution = (
                "1. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: ollama --version\n"
                "2. Ollama ì„œë²„ ì‹œì‘: ollama serve\n"
                "3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull llama3.1:8b"
            )
        elif provider == "vllm":
            solution = (
                f"1. vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸ ({base_url or 'http://localhost:8000'})\n"
                "2. ì„œë²„ ë¡œê·¸ì—ì„œ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”"
            )
        else:
            solution = (
                "1. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”\n"
                "2. API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”\n"
                "3. ì„œë¹„ìŠ¤ ìƒíƒœ í˜ì´ì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”"
            )
        
        if base_url:
            details = f"ì—°ê²° ì‹œë„: {base_url}"
        else:
            details = None
            
        super().__init__(message, solution, details)
        self.provider = provider
        self.base_url = base_url


class TemplateError(ANAError):
    """Template related errors."""
    
    def __init__(self, template_name: str, reason: str = "not_found"):
        message = f"í…œí”Œë¦¿ ì˜¤ë¥˜: {template_name}"
        solution = (
            "1. templates/ ë””ë ‰í† ë¦¬ì— í…œí”Œë¦¿ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\n"
            "2. data/templates.json íŒŒì¼ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”"
        )
        super().__init__(message, solution)


class EmbeddingError(ANAError):
    """Embedding related errors."""
    
    def __init__(self, reason: str = "model_not_found"):
        if reason == "model_not_found":
            message = "ì„ë² ë”© ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            solution = (
                "1. Ollamaì—ì„œ ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ:\n"
                "   ollama pull nomic-embed-text\n"
                "2. ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©:\n"
                "   ana config set embedding_model mxbai-embed-large"
            )
        else:
            message = "ì„ë² ë”© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            solution = "ìì„¸í•œ ì˜¤ë¥˜ ë‚´ìš©ì€ --debug í”Œë˜ê·¸ë¡œ í™•ì¸í•˜ì„¸ìš”."
        super().__init__(message, solution)


class LLMParseError(ANAError):
    """LLM response parsing errors."""
    
    def __init__(self, raw_response: str | None = None, expected_format: str = "JSON"):
        message = f"LLM ì‘ë‹µì„ {expected_format} í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        solution = (
            "1. LLM ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\n"
            "2. í”„ë¡¬í”„íŠ¸ì— í˜•ì‹ ì§€ì‹œê°€ ëª…í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”\n"
            "3. ë‹¤ë¥¸ LLM ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”"
        )
        
        details = None
        if raw_response:
            # Truncate long responses
            truncated = raw_response[:200] + "..." if len(raw_response) > 200 else raw_response
            details = f"ë°›ì€ ì‘ë‹µ: {truncated}"
        
        super().__init__(message, solution, details)
        self.raw_response = raw_response
        self.expected_format = expected_format


class RerankerError(ANAError):
    """Reranker model related errors."""
    
    def __init__(self, model_name: str, reason: str = "model_not_found"):
        if reason == "model_not_found":
            message = f"Reranker ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_name}"
            solution = (
                "1. sentence-transformersê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:\\n"
                "   pip install sentence-transformers\\n"
                "2. ëª¨ë¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸:\\n"
                "   cross-encoder/ms-marco-MiniLM-L-6-v2\\n"
                "3. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš” (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”)"
            )
        elif reason == "prediction_failed":
            message = f"Reranker ì˜ˆì¸¡ ì‹¤íŒ¨: {model_name}"
            solution = "ì…ë ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”."
        else:
            message = f"Reranker ì˜¤ë¥˜: {model_name}"
            solution = "ìì„¸í•œ ì˜¤ë¥˜ ë‚´ìš©ì€ --debug í”Œë˜ê·¸ë¡œ í™•ì¸í•˜ì„¸ìš”."
        
        super().__init__(message, solution)
        self.model_name = model_name
        self.reason = reason


def handle_error(error: Exception) -> None:
    """Generic error handler that displays user-friendly messages."""
    if isinstance(error, ANAError):
        error.display()
    else:
        # Wrap unknown errors
        ana_error = ANAError(
            message=str(error),
            solution="--debug í”Œë˜ê·¸ë¡œ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ìì„¸í•œ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
            details=error.__class__.__name__
        )
        ana_error.display()
